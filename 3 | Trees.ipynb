{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcxNoWget3XGyUN3GHY/se",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acmucsd-projects/AI-Tutorial-Resources/blob/main/3%20%7C%20Trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Trees**\n",
        "\n",
        "Contributors: Katie, Nolan\n",
        "\n"
      ],
      "metadata": {
        "id": "wsJ6RPtF-Cx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[Trees](#scrollTo=wsJ6RPtF-Cx2)\n",
        "\n",
        ">>[What is a Decision Tree? ðŸŒ²](#scrollTo=lLwFDSMgHTW5)\n",
        "\n",
        ">>[Classification vs. Regression](#scrollTo=st73yMAujg-c)\n",
        "\n",
        ">>>[Classification](#scrollTo=eyiXq2gHE86D)\n",
        "\n",
        ">>>[Regression (and Encoding)](#scrollTo=nxy50DpMlODL)\n",
        "\n",
        ">>[Hyperparameters](#scrollTo=eumrl3UzjbwP)\n",
        "\n",
        ">>>[Criterion](#scrollTo=eumrl3UzjbwP)\n",
        "\n",
        ">>>[Min Samples Split and Max Depth](#scrollTo=qENYOQ52tVE4)\n",
        "\n",
        ">>[Random Forests ðŸŒ²ðŸŒ²ðŸŒ²](#scrollTo=Q3JEjIk__eL2)\n",
        "\n",
        ">>>[Regression](#scrollTo=1_5fuqXRKqUk)\n",
        "\n",
        ">>>[Classification (and Accuracy)](#scrollTo=_eDmcuJGI-Eq)\n",
        "\n",
        ">>>[Grid Searching](#scrollTo=Q18ekTUN2XSz)\n",
        "\n",
        ">>>[XGBoost](#scrollTo=Wd_dEknvibHx)\n",
        "\n",
        ">>[The Confusion Matrix](#scrollTo=cvYFWC-IcHul)\n",
        "\n",
        ">>>[More Metrics](#scrollTo=4C68SKBLcOoi)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "BAd4qHivLB_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **What is a Decision Tree? ðŸŒ²**\n",
        "\n",
        "A decision tree is a **model that splits data into smaller groups** by asking a series of yes/no questions. The model chooses these questions based on the **features** (i.e., columns) of the data.\n",
        "\n",
        "> The goal of a decision tree is to **make accurate decisions or predictions about new data**, based on its knowledge from current data!\n",
        "\n",
        "A decision tree is a **non-parametric supervised learning** method.\n",
        "- **non-parametric**: The parameters of the model are not fixed.\n",
        "  - It learns these parameters (e.g., which feature to split, threshold value of split, etc.) through training.\n",
        "  - Linear regression, a parametric method, will always only have 2 parameters: slope and intercept.\n",
        "- **supervised learning**: The training data must have data about the feature we want to predict.\n",
        "  - To predict if someone has diabetes based on their glucose levels and BMI, we need data on other patients' glucose levels, BMI, and *whether they actually have diabetes or not*.\n",
        "  - The model is only as good as the data we give it!\n",
        "\n",
        "As the name suggests, this tree-like structure looks like this:\n",
        "\n",
        "<img src='https://waz.smartdraw.com/decision-tree/img/structure-of-a-decision-tree.png?bn=15100111939' width=500>\n",
        "\n",
        "- Root Node: The starting point of the tree! Asks the first question to split the data.\n",
        "- Decision Node: Branched from the root node or another decision node. Asks another question to split the data.\n",
        "- Leaf Node: An end point of the tree. Makes a final decision or prediction!"
      ],
      "metadata": {
        "id": "lLwFDSMgHTW5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Classification vs. Regression**\n",
        "\n",
        "A decision tree can be used to predict both categorical and numerical values!\n",
        "\n",
        "> Scikit-learn (`sklearn`), a popular machine learning library for Python, has both classification and regression models for decision trees.\n",
        "\n",
        "Classification: predicts category\n",
        "- Predict diabetes (yes, no)\n",
        "- Predict letter grade (A, B, C, D, F)\n",
        "- in `sklearn`: `DecisionTreeClassifier()`\n",
        "([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html))\n",
        "\n",
        "Regression: predicts number(s)\n",
        "- Predict age\n",
        "- Predict tomorrow's temperature and humidity\n",
        "- in `sklearn`: `DecisionTreeRegressor()` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html))"
      ],
      "metadata": {
        "id": "st73yMAujg-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Classification**\n",
        "\n",
        "We'll start with a classification example.\n",
        "\n",
        "Let's say you want to decide what top to wear today based on the weather. You have some data from 20 other days that include the temperature, chance of rain, and what you wore that day."
      ],
      "metadata": {
        "id": "eyiXq2gHE86D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "8tTg4OGdFalp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data (feel free to change any of the values)\n",
        "weather = pd.DataFrame(columns=['Temperature (ÂºF)', 'Chance of Rain (%)', 'Top'],\n",
        "                       data=[[80, 0, 't-shirt'],\n",
        "                             [70, 10, 'long sleeve'],\n",
        "                             [80, 10, 't-shirt'],\n",
        "                             [50, 100, 'raincoat'],\n",
        "                             [60, 70, 'raincoat'],\n",
        "                             [90, 0, 't-shirt'],\n",
        "                             [70, 20, 'jacket'],\n",
        "                             [80, 0, 't-shirt'],\n",
        "                             [60, 20, 'long sleeve'],\n",
        "                             [90, 10, 't-shirt'],\n",
        "                             [70, 0, 'jacket'],\n",
        "                             [70, 10, 'long sleeve'],\n",
        "                             [80, 0, 't-shirt'],\n",
        "                             [50, 0, 'jacket'],\n",
        "                             [90, 20, 't-shirt'],\n",
        "                             [70, 80, 'raincoat'],\n",
        "                             [80, 0, 't-shirt'],\n",
        "                             [60, 10, 'long sleeve'],\n",
        "                             [70, 0, 'long sleeve'],\n",
        "                             [60, 30, 'jacket']])\n",
        "weather.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OZqLzxGJFRwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we create our model, it is good practice to first split the data into two parts: **training** and **testing**.\n",
        "\n",
        "> The model will only learn from the training data, and we will evaluate its performance on the testing data it has not seen before. Since we have the actual top worn in the test set as well, we can determine how accurate the model truly is!\n",
        "\n",
        "To visualize this, let's use `train_test_split` from `sklearn`'s `model_selection` module. ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html))\n",
        "- Takes in `n` DataFrames and splits them into `n` training and `n` testing sets.\n",
        "- For our purposes, we'll split `weather` into 2 DataFrames where\n",
        "  - the first one contains all the features the model will learn from (temperature, chance of rain) and\n",
        "  - the second one contains the feature the model will predict (top).\n",
        "- We'll call these X and y."
      ],
      "metadata": {
        "id": "xhDFEUznSngY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import display # just for visual purposes"
      ],
      "metadata": {
        "id": "vyraB4BMWnr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = weather[['Temperature (ÂºF)', 'Chance of Rain (%)']]\n",
        "y = weather[['Top']]\n",
        "\n",
        "# Randomly splits the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
      ],
      "metadata": {
        "id": "Yu7puQWdWsTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice that the row indices in each set are the same\n",
        "display(X_train, y_train)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "o_YYGy3kb54q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice that the row indices in each set are the same\n",
        "display(X_test, y_test)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qL7tS3I1cUWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we're ready to create and train our model!"
      ],
      "metadata": {
        "id": "avGjRZ4jcfOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates model with default hyperparameters\n",
        "dt_class = DecisionTreeClassifier()\n",
        "\n",
        " # Trains model on only the training data\n",
        "dt_class.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "sFss71aIGA9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This doesn't show us much... We can visualize our tree using `sklearn`'s `plot_tree`. ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html))"
      ],
      "metadata": {
        "id": "NhL9WAOTeplQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import plot_tree\n",
        "import matplotlib.pyplot as plt # just for visual purposes"
      ],
      "metadata": {
        "id": "ZguFMQVHfAOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plot_tree(dt_class,\n",
        "          feature_names=X_train.columns, # must be in same order as data\n",
        "          class_names=['jacket', 'long sleeve', 'raincoat', 't-shirt'], # must be in alphabetical order\n",
        "          impurity=False\n",
        "          )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0KXUwrQTfBa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first line of each decision node is the question that determines how to split the data. The root node splits the data by `Temperature (ÂºF) <= 75.0`. Left arrows always mean `True` and right arrows always mean `False`.\n",
        "\n",
        "`samples` is number of rows in that reached that node. In the rightmost node, 6 rows *do not* have a temperature <= 75, and are classified as t-shirts.\n",
        "\n",
        "`value` shows the distribution of counts at that node. The root node is [2, 5, 2, 6], which equates to 2 jackets, 5 long sleeves, 2 raincoats, and 6 tshirts.\n",
        "\n",
        "`class` is the majority class at that node."
      ],
      "metadata": {
        "id": "js5zqqdzjKmw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Regression (and Encoding)**\n",
        "\n",
        "Let's try making a decision tree using the same `weather` DataFrame. This time, we will use the `DecisionTreeRegressor()` to predict `Temperature (ÂºF)`.\n",
        "\n"
      ],
      "metadata": {
        "id": "nxy50DpMlODL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = weather[['Chance of Rain (%)', 'Top']]\n",
        "y = weather[['Temperature (ÂºF)']]"
      ],
      "metadata": {
        "id": "Bh_swoEjs1kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One issue is that the `Top` column is categorical. A decision tree cannot use categorical data because it uses mathematical comparisons (<, >, =) to make these splits. (What is `Top <= 'jacket'`?)\n",
        "\n",
        "Decision Trees, and most machine learning models, can only use **numerical features** to help them make predictions. To combat this, we can use an **encoding technique**, or a method to convert categorical variables into numerical ones!\n",
        "\n",
        "- `X`: only numerical variables\n",
        "- `y`: either numerical or categorical variables\n",
        "\n",
        "One such technique is **One Hot Encoding**, from `sklearn`'s `preprocessing` module. ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html))"
      ],
      "metadata": {
        "id": "6rNAFgLGtjIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "greajBpKx_VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a categorical column `C`, one-hot encoding creates a separate column for each unique value in `C`. Each row gets a 1 in the column that matches its value, and 0 in all the others. Check out the example below."
      ],
      "metadata": {
        "id": "qA10ggOFz7le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create example categorical column\n",
        "top_only = pd.DataFrame(columns=['Top'],\n",
        "                        data=[['t-shirt'], ['jacket'], ['long sleeve'], ['raincoat']])\n",
        "top_only"
      ],
      "metadata": {
        "id": "XDAWn2Q90BCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create One Hot Encoder\n",
        "one_hot = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# fit: stores mapping of the data ('jacket' = [1 0 0 0], 't-shirt' = [0 0 0 1], etc.)\n",
        "# transform: applies mapping the data (converts mapping to 2D array)\n",
        "top_encoded = one_hot.fit_transform(top_only[['Top']]) # DataFrame with only categorical column(s)\n",
        "\n",
        "# Turn 2D array into DataFrame\n",
        "pd.DataFrame(data=top_encoded,\n",
        "             columns=one_hot.get_feature_names_out(['Top'])) # Column name(s), in a list"
      ],
      "metadata": {
        "id": "WoX8TdDS0flG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it's your turn! One Hot Encode the `Top` column in the `weather` DataFrame. Make sure you add the other columns back too."
      ],
      "metadata": {
        "id": "zUAVqcaAHuCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For your convenience, the weather DataFrame again\n",
        "weather.head()"
      ],
      "metadata": {
        "id": "AstHecDrLE6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One Hot Encode the `Top` column\n",
        "\n",
        "# TODO: Create One Hot Encoder and set sparse_output=False\n",
        "one_hot = ...\n",
        "\n",
        "# TODO: Use the encoder to fit and transform the `Top` column of the `weather` DataFrame\n",
        "weather_encoded = ...\n",
        "\n",
        "# TODO: Turn 2D array into DataFrame\n",
        "encoded_df = ...\n",
        "\n",
        "# TODO: Concat encoded_df with `Temperature (ÂºF)` and `Chance of Rain (%)` columns from `weather`\n",
        "encoded_df = ...\n",
        "encoded_df"
      ],
      "metadata": {
        "id": "VYPdfFCILIDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the `DecisionTreeRegressor()` and our newly encoded `encoded_df` DataFrame to predict `Temperature (ÂºF)`."
      ],
      "metadata": {
        "id": "9aEV2NwYxpMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor"
      ],
      "metadata": {
        "id": "d2h1MfdViHBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO: Define X and y and complete a train test split\n",
        "\n",
        "X = ... # which columns?\n",
        "y = ... # which columns?\n",
        "\n",
        "X_train, X_test, y_train, y_test = ..., ..., ..., ..."
      ],
      "metadata": {
        "id": "ga2VmiJ6ldQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO: Create and train a decision tree regression model\n",
        "\n",
        "dt_reg = ...\n",
        "..."
      ],
      "metadata": {
        "id": "H_yymxrdmfvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize tree! Uncomment when you're done\n",
        "\n",
        "# plt.figure(figsize=(10, 8))\n",
        "# plot_tree(dt_reg,\n",
        "#           feature_names=X_train.columns, # must be in same order as data\n",
        "#           )\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "ZfpZXTRtmtUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Answer**\n",
        "# One Hot Encode the `Top` column\n",
        "\n",
        "# TODO: Create One Hot Encoder and set sparse_output=False\n",
        "one_hot = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# TODO: Use the encoder to fit and transform the `weather` DataFrame\n",
        "weather_encoded = one_hot.fit_transform(weather[['Top']])\n",
        "\n",
        "# TODO: Turn 2D array into DataFrame\n",
        "encoded_df = pd.DataFrame(data=weather_encoded,\n",
        "                          columns=one_hot.get_feature_names_out(['Top']))\n",
        "\n",
        "# TODO: Concat encoded_df with `Chance of Rain (%)` and `Temperature (ÂºF)` columns from `weather`\n",
        "encoded_df = pd.concat([encoded_df, weather[['Chance of Rain (%)', 'Temperature (ÂºF)']]], axis=1)\n",
        "\n",
        "### TODO: Define X and y and complete a train test split\n",
        "X = encoded_df.drop(columns=['Temperature (ÂºF)']) # which columns?\n",
        "y = encoded_df['Temperature (ÂºF)'] # which columns?\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "### TODO: Create and train decision tree regression model\n",
        "dt_reg = DecisionTreeRegressor()\n",
        "dt_reg.fit(X_train, y_train)\n",
        "\n",
        "# Visualize tree! Uncomment when you're done\n",
        "plt.figure(figsize=(12, 8))\n",
        "plot_tree(dt_reg,\n",
        "          feature_names=X_train.columns, # must be in same order as data\n",
        "          )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ksqbkoLoMIy-",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you know the game, *20 Questions*, you might have noticed that decision trees follow a similar logic. They ask the \"best\" questions to help narrow down the possible answers until only one is left!\n",
        "\n",
        "> But how does a decision tree know which feature and split is the \"best\"???\n"
      ],
      "metadata": {
        "id": "8v8DSqSv-5kj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Hyperparameters**\n",
        "\n",
        "The `DecisionTreeClassifier()` and `DecisionTreeRegressor()` have many **hyperparameters**, such as `criterion`, `min_samples_split`, `max_depth`, etc. These are different than *parameters* because we get to choose them, rather than the model.\n",
        "\n",
        "### **Criterion**\n",
        "\n",
        "The `criterion` hyperparameter **controls how the tree decides to split the data**. They utilize mathematical formulas to decide which split is the best!\n",
        "\n",
        "Classifiers and Regressors have different criterion. Some examples include:\n",
        "- For classification:\n",
        "  - [Gini impurity](https://www.learndatasci.com/glossary/gini-impurity/): `criterion = 'gini'` (default)\n",
        "  - [Entropy](https://www.geeksforgeeks.org/how-to-calculate-entropy-in-decision-tree/): `criterion = 'entropy'`\n",
        "\n",
        "- For regression:\n",
        "  - [Mean squared error](https://www.geeksforgeeks.org/retrieving-node-mse-in-decisiontreeregressor/): `criterion = 'squared_error'` (default)\n",
        "  - [Mean absolute error](https://www.geeksforgeeks.org/how-to-calculate-mean-absolute-error-in-python/): `criterion = 'absolute_error'`\n",
        "\n",
        "We won't go in detail about them in this notebook, but feel free to read more about them by clicking on each link.\n",
        "\n",
        "Since our regression model from earlier was created using the default hyperparameters, it's **criterion** is **mean squared error**. Let's check out the predictions! (Make sure to run the cells in the Answer section if you didn't fill out the code!)"
      ],
      "metadata": {
        "id": "eumrl3UzjbwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "ks2TaL0aln_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The .predict() method generates predictions based on the trained model\n",
        "y_train_pred = dt_reg.predict(X_train)\n",
        "y_test_pred = dt_reg.predict(X_test)\n",
        "\n",
        "# Test the MSE of the training set\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "\n",
        "# Test the MSE of the testing set\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "print('Training Set MSE: ', train_mse)\n",
        "print('Testing Set MSE: ', test_mse)"
      ],
      "metadata": {
        "id": "4sT6TWUgXerP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do these mean? MSE is the **average squared difference** between the actual and predicted temperatures. So the training MSE of ~24 doesn't mean that the model was 24Âº off, but rather $\\sqrt{24}$ ~5Âº! Similarly, the testing MSE is $\\sqrt{49}$ ~7Âº.\n",
        "\n",
        "Let's visualize the predictions vs. actual temperatures."
      ],
      "metadata": {
        "id": "LrFKKe4-nJJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pd.DataFrame({'actual temp': y_train})\n",
        "predictions['predicted temp'] = y_train_pred\n",
        "predictions"
      ],
      "metadata": {
        "id": "F_N7bW3EkyDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pretty good! But remember we trained the model with this data. We will see the model's true performance by looking at the test set's predictions."
      ],
      "metadata": {
        "id": "4XfXvP3gpcYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pd.DataFrame({'actual temp': y_test})\n",
        "predictions['predicted temp'] = y_test_pred\n",
        "predictions"
      ],
      "metadata": {
        "id": "HeEL5aYcnZ_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Still pretty good, but we can see larger differences (60 vs. 70)."
      ],
      "metadata": {
        "id": "6nFvsm_jr9Pj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Min Samples Split and Max Depth**\n",
        "\n",
        "Ultimately, we want to use hyperparameters to make sure the training and testing MSE (or other criterion) are both low in value and similar to one another. Decision trees tend to **overfit** the training data, which means that the **model might work really well for the data it was trained on, but not as effectively for unseen data**. This is because decision trees, by default, keep splitting the data until every specific detail of the training data is found, rather than finding general patterns.\n",
        "\n",
        "The `min_samples_split` and `max_depth` hyperparameters can help reduce overfitting by limiting when the tree can split.\n",
        "- `min_samples_split` (int): sets the minimum number of samples required to split a node (default=`2`)\n",
        "- `max_depth` (int): sets the maximum number of levels a tree can split from root to leaf (default=`None`)\n",
        "\n",
        "Let's try visualizing a new `DecisionTreeRegressor()` to have a `min_samples_split` of 5 and `max_depth` of 3."
      ],
      "metadata": {
        "id": "qENYOQ52tVE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_new = DecisionTreeRegressor(min_samples_split=5, max_depth=3)\n",
        "dt_new.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Al3kUDwptU1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "plot_tree(dt_new,\n",
        "          feature_names=X_train.columns, # must be in same order as data\n",
        "          )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4WNsOJFaps1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, no split has a sample less than 5 and the entire tree has a maximum depth of 3.\n",
        "\n",
        "Let's see if this changed our MSEs."
      ],
      "metadata": {
        "id": "gM9nu-yZzbrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The .predict() method generates predictions based on the trained model\n",
        "new_train_pred = dt_new.predict(X_train)\n",
        "new_test_pred = dt_new.predict(X_test)\n",
        "\n",
        "# Test the MSE of the training set\n",
        "train_mse_new = mean_squared_error(y_train, new_train_pred)\n",
        "\n",
        "# Test the MSE of the testing set\n",
        "test_mse_new = mean_squared_error(y_test, new_test_pred)\n",
        "\n",
        "print('Training Set MSE: ', train_mse_new)\n",
        "print('Testing Set MSE: ', test_mse_new)"
      ],
      "metadata": {
        "id": "jAeKRayZyX-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Though the MSE is worse for the training set, it is actually **better** for the testing set. In addition, the values are closer to one another, making the model more generalizable!\n",
        "\n",
        "Your turn! Create a new `DecisionTreeRegressor()` with `criterion='absolute_error'`, `min_samples_split=4`, and `max_depth=4`. Print out the MSEs for the training and testing sets."
      ],
      "metadata": {
        "id": "coOSPPIP0Bx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Create new regressor and fit to training data\n",
        "dt_abs = ...\n",
        "...\n",
        "\n",
        "# TODO: Use .predict() to generate predictions\n",
        "abs_train_pred = ...\n",
        "abs_test_pred = ...\n",
        "\n",
        "# TODO: Find the MAE of the training set\n",
        "train_mae = ...\n",
        "\n",
        "# TODO: Find the MAE of the testing set\n",
        "test_mae = ...\n",
        "\n",
        "print('Training Set MAE: ', train_mae)\n",
        "print('Testing Set MAE: ', test_mae)"
      ],
      "metadata": {
        "id": "pg4YU5pf0BXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Better or worse than MSE? Depending on the dataset, some criterion are better than others..."
      ],
      "metadata": {
        "id": "uDH1o_yr1kxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Answer**\n",
        "# TODO: Create new regressor and fit to training data\n",
        "dt_abs = DecisionTreeRegressor(criterion='absolute_error', min_samples_split=4, max_depth=4)\n",
        "dt_abs.fit(X_train, y_train)\n",
        "\n",
        "# TODO: Use .predict() to generate predictions\n",
        "abs_train_pred = dt_abs.predict(X_train)\n",
        "abs_test_pred = dt_abs.predict(X_test)\n",
        "\n",
        "# TODO: Find the MAE of the training set\n",
        "train_mse_abs = mean_squared_error(y_train, abs_train_pred)\n",
        "\n",
        "# TODO: Find the MAE of the testing set\n",
        "test_mse_abs = mean_squared_error(y_test, abs_test_pred)\n",
        "\n",
        "print('Training Set MAE: ', train_mse_abs)\n",
        "print('Testing Set MAE: ', test_mse_abs)"
      ],
      "metadata": {
        "id": "cVHXi1Wcz2Lf",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Random Forests ðŸŒ²ðŸŒ²ðŸŒ²**\n",
        "\n",
        "Now that we know the basic structure of decision tree models, we'll introduce **Random Forests**.\n",
        "> Just as a forest is an area with many trees, a **random forest** is a **model** with many **decision trees**!\n",
        "\n",
        "<img src=\"https://serokell.io/files/vz/vz1f8191.Ensemble-of-decision-trees.png\" width=500>\n",
        "\n",
        "We call it a *random* forest because this machine learning algorithm uses **bootstrapping** and **random feature selection** in each decision tree.\n",
        "- **Bootstrapping**: For each decision tree in the forest, we randomly select data points from the original dataset, but with replacement. A single data point can be selected more than once, while others might not be selected at all.\n",
        "- **Random Feature Selection**: Each decision tree randomly chooses a few columns (features) from the data to learn from.\n",
        "\n",
        "> *These strategies ensure that each tree learns from a slightly different version of the dataset and helps the model avoid overfitting.*\n",
        "\n",
        "Random Forests can be used for both classification and regression tasks:\n",
        "- **Classification**: Each tree produces a categorical prediction, and the final result is the **category** chosen by the **majority** of trees (majority voting).\n",
        "- **Regression**: Each tree produces a numerical prediction, and the final result is the **average** of all the individual predictions.\n",
        "\n",
        "From `sklearn`'s `ensemble` module, we use **`RandomForestClassifier`** ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)) and **`RandomForestRegressor`** ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)) to create these models. They both have similar hyperparameters to decision trees, such as `criterion`, `max_depth`, and `min_samples_split`.\n",
        "> One **new** hyperparameter is **`n_estimators`**, which decides the **number of decision trees** the model uses (default is 100).\n"
      ],
      "metadata": {
        "id": "Q3JEjIk__eL2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Regression**\n",
        "\n",
        "We'll explore the regressor first, and you will try a classifier on your own.\n"
      ],
      "metadata": {
        "id": "1_5fuqXRKqUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Turn data into DataFrame\n",
        "housing = pd.DataFrame(data=fetch_california_housing().data, columns=fetch_california_housing().feature_names)\n",
        "housing['value'] = fetch_california_housing().target"
      ],
      "metadata": {
        "id": "CkPaG41l8ZiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `housing` DataFrame contains data about California housing in \"block groups,\" which is an area with about 600 - 3,000 people. The `value` column contains the median price of a block, in hundreds of thousands of dollars (e.g., 4.2 ~ 420,000). See the dataset and description below for further info on the other columns."
      ],
      "metadata": {
        "id": "beZ_bQLRXmLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing.head()"
      ],
      "metadata": {
        "id": "eonvCBN0vlIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(fetch_california_housing().DESCR)"
      ],
      "metadata": {
        "id": "FkSmnbJYYxjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use the `RandomForestRegressor` to train a model to predict the median house value given the other features. We follow a similar process as before:\n",
        "1. Encode categorical data (if necessary)\n",
        "2. Split X and y data into train and test sets\n",
        "3. Create model and fit training data\n",
        "4. Generate predictions on the testing data\n",
        "5. Compare actual and predicted values using metric(s)\n",
        "6. Adjust hyperparameters to improve model and metric"
      ],
      "metadata": {
        "id": "F47iElEpbb_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2\n",
        "X = housing.drop(columns='value')\n",
        "y = housing['value']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "# Step 3\n",
        "forest_reg = RandomForestRegressor()\n",
        "forest_reg.fit(X_train, y_train)\n",
        "\n",
        "# Step 4\n",
        "y_pred = forest_reg.predict(X_test)\n",
        "\n",
        "# Step 5\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'MSE: {mse:.4f}, which implies that the average prediction is about {mse**0.5:.4f} off, or ${(mse**0.5)*100000:.2f} off.')\n",
        "\n",
        "# Step 6: Adjust hyperparameters in Step 3 and rerun. Feel free to try this on your own!"
      ],
      "metadata": {
        "id": "0nZnbnERWOly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Classification (and Accuracy)**\n",
        "\n",
        "The `criterion` and evaluation metric of a model does not need to be the same. In fact, it's common (in classification) to use a `criterion` like Gini impurity or entropy during training, while evaluating model performance using a metric such as **accuracy**.\n",
        "\n",
        "- The **accuracy** of a model is the **proportion** of **correct predictions** out of **all predictions** made.\n",
        "  - *Easy to interpret* and provides a *general sense of performance*.\n",
        "  - Best used when the classes within a categorical variable are *balanced and equally represented*.\n",
        "\n",
        "$$\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}$$\n",
        "\n",
        "- For instance, given a dataset of 3 cats and 2 dogs, if I predict 2 cats and 2 dogs correctly, my accuracy is $\\frac{4}{5} = 0.8$.\n",
        "\n",
        "> **In `sklearn`, the `metrics` module can calculate accuracy using the `accuracy_score` function**. ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html))\n",
        "\n",
        "\n",
        "\n",
        "**Your turn**! The `forest` DataFrame (how fitting!), seen below, contains data on 30x30m patches of forest in the US.\n",
        "- The `type` column is each patch's cover type, which is the dominant species of tree, as an **integer 1-7**.\n",
        "- See more info on each feature column [here](https://archive.ics.uci.edu/dataset/31/covertype). There are 54 features, so it's a good idea to set some hyperparameters to limit overfitting and save time!\n",
        "\n",
        "Use the `RandomForestClassifier` to train a model to predict a patch's cover type. Try to achieve an **accuracy above 90% within 2 minutes**!"
      ],
      "metadata": {
        "id": "_eDmcuJGI-Eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_covtype\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Turn data into DataFrame\n",
        "forest = pd.DataFrame(data=fetch_covtype().data, columns=fetch_covtype().feature_names)\n",
        "forest['type'] = fetch_covtype().target"
      ],
      "metadata": {
        "id": "MKtuer4mEnzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forest.head()"
      ],
      "metadata": {
        "id": "NOUR1rZTimov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(fetch_covtype().DESCR)"
      ],
      "metadata": {
        "id": "zEn9_ZcQmCha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# TODO: Create a RandomForestClassifier that predicts the cover type of a patch.\n",
        "# Try out various hyperparameters such that your code runs within 2 minutes\n",
        "# and your accuracy is above 0.9!\n",
        "\n",
        "..."
      ],
      "metadata": {
        "id": "K9xbgdxIilQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QhJyWW1YsOMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mzI8ttBXikPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Answer**\n",
        "%%time\n",
        "# TODO: Create a RandomForestClassifier that predicts the cover type of a patch.\n",
        "# Try out various hyperparameters such that your code runs within 2 minutes\n",
        "# and your accuracy is above 0.9!\n",
        "\n",
        "X = forest.drop(columns='type')\n",
        "y = forest['type']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "# Note your hyperparameters can be different\n",
        "forest_cls = RandomForestClassifier(n_estimators=50, max_depth=100, min_samples_split=10)\n",
        "\n",
        "# Takes a while to run (~1.5 mins)\n",
        "forest_cls.fit(X_train, y_train)\n",
        "\n",
        "y_pred = forest_cls.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_pred, y_test)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "209CH3l-if2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Grid Searching**\n",
        "\n",
        "As of now, we've manually chosen our hyperparameters through trial and error. While this approach does provide valuable intuition about how different parameters affect model performance, it's often inefficient, subjective, and may lead to suboptimal results (especially as the number of hyperparameters increase).\n",
        "\n",
        "A more systematic and unbiased approach is to use automated hyperparameter tuning methods, one of the most common being **grid search**.\n",
        "\n",
        "> Grid searching tests every possible combination of values from a list you provide and evaluates each one by training and testing the model multiple times on different splits of the data to find the best-performing setup.\n",
        "\n",
        "`sklearn`'s `model_selection` module allows us to grid search using the **`GridSearchCV`** function. ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html))\n",
        "\n",
        "> \"CV\" stands for Cross-Validation, a method used to make sure a machine learning model works well on new, unseen data. Instead of training and testing the model just once, cross-validation splits the data into several parts (called *folds*). The model is trained on some parts and tested on the rest, then this is repeated several times using different splits. This helps prevent overfitting and gives a more accurate picture of how the model will perform in real-world situations.\n",
        "\n",
        "That being said, we might make a dictionary of lists like this to create our grid of possible hyperparameter combinations:\n",
        "\n",
        "<pre>\n",
        "param_grid = {\n",
        "  n_estimators: [50, 100, 150],\n",
        "  max_depth: [None, 10, 20],\n",
        "  min_samples_split: [3, 5, 10]\n",
        "}\n",
        "</pre>\n",
        "\n",
        "And our new model like this:\n",
        "\n",
        "<pre>\n",
        "forest_cls = RandomForestClassifier()\n",
        "\n",
        "grid_search = GridSearchCV(estimator=forest_cls, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "</pre>\n",
        "\n",
        "This would result in our model trying and comparing 3 `n_estimators` x 3 `max_depth` x 3 `min_samples_split` x 5 folds = 135 different random forests for the best accuracy. The order in which the algorithm cycles through the hyperparameters looks like this:\n",
        "1. `n_estimators=50`, `max_depth=None`, `min_samples_split=3`\n",
        "2. `n_estimators=50`, `max_depth=None`, `min_samples_split=5`\n",
        "3. `n_estimators=50`, `max_depth=None`, `min_samples_split=10`\n",
        "4. `n_estimators=50`, `max_depth=10`, `min_samples_split=3`\n",
        "5. `n_estimators=50`, `max_depth=10`, `min_samples_split=5`\n",
        "6. And so on.\n",
        "\n",
        "This can be time consuming, but very rewarding to achieve a great model. We'll explore how to fully code this in the next section!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q18ekTUN2XSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **XGBoost**\n",
        "\n",
        "XGBoost stands for **extreme gradient boosting**. This algorithm, like random forests, uses many decision trees to make predictions. However, the **key difference** is that it builds these trees **sequentially**, rather than independentally.\n",
        "> This means that each new decision tree learns from the errors of the previous ones!\n",
        "\n",
        "The learning process in XGBoost is as follows:\n",
        "1. Assign **equal weights** to all instances (an instance is one row of the data).\n",
        "2. Train first model on this equally weighed data. Its performance determines how the instance weights are adjusted.\n",
        "  - Instances that are **predicted well receive lower weights**, while those **predicted poorly are given higher weights**.\n",
        "3. Train second model on this updated data, focusing more on the difficult cases the first model struggled with.\n",
        "4. Train third model, fourth model, etc...\n",
        "  - Each new model aims to **correct the errors of the previous ones**, gradually improving overall accuracy!\n",
        "  - However, this causes XGBoost to be more prone to overfitting, so it is important to adjust the hyperparameters of the function.\n",
        "\n",
        "> How does the algorithm do this? **Gradient Descent Optimization!** Feel free to read more about gradient descent [here](https://www.ibm.com/think/topics/gradient-descent), or check out [this video](https://www.youtube.com/watch?v=TyvYZ26alZs&ab_channel=Econoscent) on XGBoost to visualize it better.\n",
        "\n",
        "From the `xgboost` module, we can use the `XGBClassifier` and `XGBRegressor` to create these models.\n",
        "- Check out their documentations: [`xgboost`](https://xgboost.readthedocs.io/en/release_3.0.0/index.html), [`XGBClassifier`](https://cloud.google.com/python/docs/reference/bigframes/latest/bigframes.ml.ensemble.XGBClassifier), [`XGBRegressor`](https://cloud.google.com/python/docs/reference/bigframes/latest/bigframes.ml.ensemble.XGBRegressor)\n",
        "\n",
        "In the previous question, we predicted the cover type of a forest patch using `RandomForestClassifier`. Let's try doing the same with the `XGBClassifier` and compare our results!\n",
        "\n"
      ],
      "metadata": {
        "id": "Wd_dEknvibHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "\n",
        "# The `forest` DataFrame again, for your convenience\n",
        "forest.head()"
      ],
      "metadata": {
        "id": "qTtLIoELielK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = forest.drop(columns='type')\n",
        "y = forest['type']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "metadata": {
        "id": "SvaR2o7ps-xM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The XGBClassifier internally expects class labels to start at 0 and be contiguous integers (0, 1, 2...). However, our labels range from 1 to 7. We'll use a `LabelEncoder` to adjust this! ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html))"
      ],
      "metadata": {
        "id": "fOlIGWwAxp8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment to see the unadjusted error\n",
        "\n",
        "# forest_xgb = XGBClassifier()\n",
        "# forest_xgb.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "hUVJshPQx9Ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train_enc = le.fit_transform(y_train)\n",
        "y_test_enc = le.transform(y_test) # use .transform, rather than .fit_transform, to avoid possible mismatches\n",
        "\n",
        "forest_xgb = XGBClassifier(n_estimators=50, eval_metric='error') # limit number of trees to 50, 'error' = accuracy\n",
        "\n",
        "# Create a list of possible values to try for each hyperparameter\n",
        "param_grid = {\n",
        "    'gamma': [0.2, 0.3],\n",
        "    'max_depth': [10, 12],\n",
        "    'subsample': [0.6, 0.8]\n",
        "}\n",
        "\n",
        "# Create grid search with 3 folds and choose combination with best accuracy\n",
        "grid_search = GridSearchCV(estimator=forest_xgb, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Takes a while to run (~12 mins)\n",
        "grid_search.fit(X_train, y_train_enc)"
      ],
      "metadata": {
        "id": "a2Y5kmBLyK2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best parameter combination and score\n",
        "print(\"Best parameters found:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy:\", grid_search.best_score_)\n",
        "\n",
        "# Get best model and evaluate accuracy on test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"Test set accuracy:\", accuracy_score(y_test_enc, y_pred))"
      ],
      "metadata": {
        "id": "8WrwgaOGz4qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best combination of hyperparameters (that we tested) is `gamma=0.3`, `max_depth=12`, and `subsample=0.6`, which achieved a 95% accuracy!\n",
        "\n",
        "Your turn! Use the `XGBRegressor` to predict the median house value of a block group. You can use grid search, but it's not required (in the interest of time). Compare its MSE to our `RandomForestRegressor`!"
      ],
      "metadata": {
        "id": "C3mna9O0spzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The `housing` DataFrame again, for your convenience\n",
        "housing.head()"
      ],
      "metadata": {
        "id": "2k4QpC0aswVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "\n",
        "..."
      ],
      "metadata": {
        "id": "tiyAFcPcu2HM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Answer**\n",
        "\n",
        "X = housing.drop(columns='value')\n",
        "y = housing['value']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "# Without grid search\n",
        "housing_xgb = XGBRegressor(n_estimators=50, eval_metric='rmse') # limit number of trees to 50, 'rmse' = root mean squared error\n",
        "housing_xgb.fit(X_train, y_train) # ~3 secs\n",
        "\n",
        "y_pred = housing_xgb.predict(X_test)\n",
        "rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "\n",
        "print(f'RMSE: {rmse:.4f}, which implies that the average prediction is about ${rmse*100000:.2f} off.')\n",
        "\n",
        "\n",
        "# With grid search\n",
        "housing_xgb = XGBRegressor(n_estimators=100, eval_metric='rmse')\n",
        "\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [3, 6],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'min_child_weight': [1, 5],\n",
        "    'reg_alpha': [0, 0.1],\n",
        "    'reg_lambda': [1, 5]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=housing_xgb, param_grid=param_grid, cv=3, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train) # ~3 mins\n",
        "\n",
        "best_rmse = -grid_search.best_score_\n",
        "print(\"Best RMSE:\", best_rmse)\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "\n",
        "print(f'RMSE: {rmse:.4f}, which implies that the average prediction is about ${rmse*100000:.2f} off.')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HtcKgFdiLZKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In general, XGBoost classification takes longer than regression due to added complexity:\n",
        "- Label encoding is required for classification but not for regression.\n",
        "- Multiclass classification builds one tree per class per round (e.g., 3 classes = 3x more trees).\n",
        "- And more...\n",
        "\n",
        "So even with similar data and settings, classification is slower because it does more computationally expensive procedures.\n",
        "\n"
      ],
      "metadata": {
        "id": "bi3lx2CTQwyT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **The Confusion Matrix**\n",
        "\n",
        "A **confusion matrix** is a table used to evaluate the performance of a **classification model** by comparing the predicted labels with the actual labels. It is especially useful in binary and multiclass classification problems.\n",
        "\n",
        "<img src='https://plat.ai/wp-content/uploads/Table1-2.png.webp' width=500>\n",
        "\n",
        "- **True Positive (TP)**: The model correctly predicted the positive class.\n",
        "\n",
        "- **True Negative (TN)**: The model correctly predicted the negative class.\n",
        "\n",
        "- **False Positive (FP)**: The model incorrectly predicted positive when it is actually negative (Type I error).\n",
        "\n",
        "- **False Negative (FN)**: The model incorrectly predicted negative when it is actually positive (Type II error).\n",
        "\n",
        "In context of the confusion matrix, the formula of accuracy (overall proportion of correct predictions) can also be written as:\n",
        "\n",
        "$$\\text{Accuracy} = \\frac{\\text{TP + TN}}{\\text{TP + TN + FP + FN}}$$\n"
      ],
      "metadata": {
        "id": "cvYFWC-IcHul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **More Metrics**\n",
        "\n",
        "Classification models have many other metrics, such as **precision, recall, and F1-score**. Each has their own situational benefits:\n",
        "\n",
        "**Precision**: Out of all the instances the model predicted as positive, how many were **actually positive?**\n",
        "- A **high precision** indicates your model's positive predictions are **mostly correct** (few false positives).\n",
        "- A **low precision** indicates your model's positive predictions are **mostly incorrect** (many false positives).\n",
        "> This would be a good metric to use when **false positives are costly**. For example, in an email spam filter, you would want to avoid marking real emails as spam.\n",
        "\n",
        "$$\\text{Precision} = \\frac{\\text{TP}}{\\text{TP + FP}}$$\n",
        "\n",
        "**Recall**: Out of all actual positive instances, how many did the model correctly identify?\n",
        "- A **high recall** indicates your model **identifies** most of the actual positives (few false negatives).\n",
        "- A **low recall** indicates your model **misses** most of the actual positives (many false negatives).\n",
        "> This would be a good metric to use when **missing a positive is costly**. For example, in a disease detection model, you would want to catch as many sick patients as possible.\n",
        "\n",
        "$$\\text{Recall} = \\frac{\\text{TP}}{\\text{TP + FN}}$$\n",
        "\n",
        "**F1-Score**: The harmonic (lower) mean of precision and recall.\n",
        "- A **high F1-Score** means there is a **good balance** between precision and recall (few false positives and few false negatives).\n",
        "- A **low F1-Score** means there is a **poor balance** between precision and recall (many false positives and/or many false negatives).\n",
        "> This would be a good metric to use when you want to **balance false positives and false negatives** and need a single metric. Also useful when **classes are imbalanced**.\n",
        "\n",
        "\n",
        "\n",
        "$$\\text{F1-Score} = 2 * \\frac{\\text{Precision * Recall}}{\\text{Precision + Recall}}$$\n",
        "\n",
        "For regression, one other metric (besides RMSE, MSE, MAE) is the **Coefficient of Determination ($R^2$)**, which tells you how well your model fits the data.\n",
        "\n",
        "It outputs a number between 0 and 1 (sometimes even negative if the model is really bad), which tells you:\n",
        "- 0: Your model explains **none** of the variation in the data.\n",
        "- 1: Your model explains **all** of the variation perfectly.\n",
        "- In between: Your model explains **some**, but not all, of the variation.\n",
        "\n",
        "Feel free to read more [here](https://www.scribbr.com/statistics/coefficient-of-determination/)!\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4C68SKBLcOoi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this final question, calculate the accuracy, precision, and recall of this confusion matrix:\n",
        "\n",
        "|                      | Predicted Positive | Predicted Negative |\n",
        "|----------------------|--------------------|--------------------|\n",
        "| Actual Positive      |        50 (TP)      |       10 (FN)       |\n",
        "| Actual Negative      |         5 (FP)      |       35 (TN)       |\n"
      ],
      "metadata": {
        "id": "FsASmwq5bZ7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "\n",
        "accuracy = ...\n",
        "print('Accuracy: ', accuracy)\n",
        "\n",
        "precision = ...\n",
        "print('Precision: ', precision)\n",
        "\n",
        "recall = ...\n",
        "print('Recall: ', recall)"
      ],
      "metadata": {
        "id": "NM2nu-j0cLga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Answer**\n",
        "\n",
        "accuracy = (50 + 35) / (50 + 10 + 5 + 35)\n",
        "print('Accuracy: ', accuracy)\n",
        "\n",
        "precision = (50) / (50 + 5)\n",
        "print('Precision: ', precision)\n",
        "\n",
        "recall = (50) / (50 + 10)\n",
        "print('Recall: ', recall)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SwTO39e1bxTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5rfCC43bco_B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}